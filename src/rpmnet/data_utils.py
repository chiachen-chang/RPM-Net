"""
Data utilities for RPM-Net

Includes data loading and preprocessing functions
"""

import numpy as np
import pickle
import os
import torch
from torch.utils.data import DataLoader, TensorDataset


def load_data(data_dir, dataset_name="unsw"):
    """åŠ è½½å¤„ç†å¥½çš„æ•°æ®é›†"""
    print(f"ğŸ”„ æ­£åœ¨åŠ è½½{dataset_name.upper()}æ•°æ®é›†...")
    
    try:
        # åŠ è½½è®­ç»ƒæ•°æ®
        X_train = np.load(os.path.join(data_dir, f'X_train_{dataset_name}.npy'))
        y_train = np.load(os.path.join(data_dir, f'y_train_{dataset_name}.npy'))
        
        # åŠ è½½å·²çŸ¥ç±»æµ‹è¯•æ•°æ®
        X_test_known = np.load(os.path.join(data_dir, f'X_test_known_{dataset_name}.npy'))
        y_test_known = np.load(os.path.join(data_dir, f'y_test_known_{dataset_name}.npy'))
        
        # åŠ è½½éªŒè¯æœªçŸ¥ç±»æ•°æ®
        X_validation_unknown = np.load(os.path.join(data_dir, f'X_validation_unknown_{dataset_name}.npy'))
        y_validation_unknown = np.load(os.path.join(data_dir, f'y_validation_unknown_{dataset_name}.npy'))
        
        # åŠ è½½æµ‹è¯•æœªçŸ¥ç±»æ•°æ®
        X_test_unknown = np.load(os.path.join(data_dir, f'X_test_unknown_{dataset_name}.npy'))
        y_test_unknown = np.load(os.path.join(data_dir, f'y_test_unknown_{dataset_name}.npy'))
        
        # åŠ è½½ç±»åˆ«ä¿¡æ¯
        with open(os.path.join(data_dir, f'class_info_{dataset_name}.pkl'), 'rb') as f:
            class_info = pickle.load(f)
        
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
        print(f"   è®­ç»ƒé›†: {X_train.shape}")
        print(f"   å·²çŸ¥ç±»æµ‹è¯•é›†: {X_test_known.shape}")
        print(f"   éªŒè¯æœªçŸ¥ç±»: {X_validation_unknown.shape}")
        print(f"   æµ‹è¯•æœªçŸ¥ç±»: {X_test_unknown.shape}")
        print(f"   ç‰¹å¾æ•°é‡: {X_train.shape[1]}")
        print(f"   å·²çŸ¥ç±»åˆ«: {class_info['known_classes']}")
        print(f"   éªŒè¯æœªçŸ¥ç±»åˆ«: {class_info.get('validation_unknown_classes', [])}")
        print(f"   æµ‹è¯•æœªçŸ¥ç±»åˆ«: {class_info['test_unknown_classes']}")
        
        return {
            'train': (X_train, y_train),
            'test_known': (X_test_known, y_test_known),
            'validation_unknown': (X_validation_unknown, y_validation_unknown),
            'test_unknown': (X_test_unknown, y_test_unknown)
        }, class_info
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        raise e


def prepare_data_loaders(data, class_info, config):
    """å‡†å¤‡PyTorchæ•°æ®åŠ è½½å™¨"""
    print("ğŸ”„ å‡†å¤‡æ•°æ®åŠ è½½å™¨...")
    
    # åˆ›å»ºæ ‡ç­¾åˆ°ç´¢å¼•çš„æ˜ å°„
    known_classes = class_info['known_classes']
    label_to_idx = {label: idx for idx, label in enumerate(known_classes)}
    idx_to_label = {idx: label for label, idx in label_to_idx.items()}
    
    print(f"ğŸ“‹ æ ‡ç­¾æ˜ å°„: {label_to_idx}")
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X_train, y_train = data['train']
    y_train_idx = np.array([label_to_idx[label] for label in y_train])
    
    train_dataset = TensorDataset(
        torch.FloatTensor(X_train),
        torch.LongTensor(y_train_idx)
    )
    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)
    
    # å‡†å¤‡å·²çŸ¥ç±»æµ‹è¯•æ•°æ®
    X_test_known, y_test_known = data['test_known']
    y_test_known_idx = np.array([label_to_idx[label] for label in y_test_known])
    
    test_known_dataset = TensorDataset(
        torch.FloatTensor(X_test_known),
        torch.LongTensor(y_test_known_idx)
    )
    test_known_loader = DataLoader(test_known_dataset, batch_size=config.BATCH_SIZE, shuffle=False)
    
    # å‡†å¤‡éªŒè¯é›†æœªçŸ¥ç±»æ•°æ®
    X_validation_unknown, y_validation_unknown = data['validation_unknown']
    validation_unknown_dataset = TensorDataset(torch.FloatTensor(X_validation_unknown))
    validation_unknown_loader = DataLoader(validation_unknown_dataset, batch_size=config.BATCH_SIZE, shuffle=False)
    
    # ä¸ºæ¯ä¸ªæµ‹è¯•æœªçŸ¥ç±»åˆ›å»ºå•ç‹¬çš„åŠ è½½å™¨
    print("  åˆ›å»ºæµ‹è¯•æœªçŸ¥ç±»æ•°æ®åŠ è½½å™¨...")
    X_test_unknown, y_test_unknown = data['test_unknown']
    
    test_unknown_loaders = {}
    
    # è·å–æ‰€æœ‰æµ‹è¯•æœªçŸ¥ç±»åˆ«
    test_unknown_classes = class_info['test_unknown_classes']
    
    for unknown_class in test_unknown_classes:
        # æ‰¾åˆ°è¯¥æœªçŸ¥ç±»çš„æ ·æœ¬
        mask = y_test_unknown == unknown_class
        X_unknown_class = X_test_unknown[mask]
        
        if len(X_unknown_class) > 0:
            unknown_dataset = TensorDataset(torch.FloatTensor(X_unknown_class))
            unknown_loader = DataLoader(unknown_dataset, batch_size=config.BATCH_SIZE, shuffle=False)
            test_unknown_loaders[unknown_class] = unknown_loader
            print(f"   ç±»åˆ« {unknown_class}: {len(X_unknown_class)} æ ·æœ¬")
    
    print(f"âœ… æ•°æ®åŠ è½½å™¨å‡†å¤‡å®Œæˆ!")
    print(f"   è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset)}")
    print(f"   å·²çŸ¥ç±»æµ‹è¯•é›†å¤§å°: {len(test_known_loader.dataset)}")
    print(f"   éªŒè¯é›†æœªçŸ¥ç±»å¤§å°: {len(validation_unknown_loader.dataset)}")
    print(f"   æµ‹è¯•æœªçŸ¥ç±»ç§ç±»æ•°: {len(test_unknown_loaders)}")
    
    return train_loader, test_known_loader, validation_unknown_loader, test_unknown_loaders, label_to_idx, idx_to_label


def compute_class_weights(train_loader, idx_to_label):
    """è®¡ç®—ç±»åˆ«æƒé‡å¤„ç†ä¸å¹³è¡¡é—®é¢˜"""
    all_labels = []
    for _, labels in train_loader:
        all_labels.extend(labels.numpy())
    y_train = np.array(all_labels)
    
    # è·å–è®­ç»ƒé›†ä¸­æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡
    unique_classes, class_counts = np.unique(y_train, return_counts=True)
    
    # è®¡ç®—ç±»åˆ«æƒé‡ - æ ·æœ¬æ•°é‡è¶Šå°‘ï¼Œæƒé‡è¶Šå¤§
    weights = np.max(class_counts) / class_counts
    
    # å½’ä¸€åŒ–æƒé‡
    weights = weights / np.sum(weights) * len(unique_classes)
    
    # åˆ›å»ºç±»åˆ«ç´¢å¼•åˆ°æƒé‡çš„æ˜ å°„
    class_weights = {int(cls): float(weight) for cls, weight in zip(unique_classes, weights)}
    
    print("ğŸ“Š ç±»åˆ«æƒé‡:")
    for cls, weight in class_weights.items():
        print(f"   ç±»åˆ« {cls} ({idx_to_label[cls]}): {weight:.4f}")
    
    return class_weights
